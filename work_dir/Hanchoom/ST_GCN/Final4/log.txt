[ Wed Dec 14 07:34:59 2022 ] Parameters:
{'work_dir': './work_dir/Hanchoom/ST_GCN/Final4', 'config': 'config/st_gcn/hanchoom/train.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 5, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'st_gcn.feeder.Feeder_hanchoom', 'num_worker': 128, 'train_feeder_args': {'mode': 'train', 'data_path': './data_hanchoom_final/hanchoom_train', 'label_path': './data_hanchoom_final/hanchoom_train_label.json', 'random_choose': True, 'random_move': True, 'window_size': 100}, 'test_feeder_args': {'mode': 'test', 'data_path': './data_hanchoom_final/hanchoom_val', 'label_path': './data_hanchoom_final/hanchoom_val_label.json', 'window_size': 100}, 'model': 'st_gcn.net.ST_GCN', 'model_args': {'num_class': 8, 'channel': 3, 'window_size': 100, 'num_person': 1, 'num_point': 18, 'dropout': 0.3, 'graph': 'st_gcn.graph.Hanchoom', 'graph_args': {'labeling_mode': 'spatial'}, 'mask_learning': True, 'use_data_bn': True}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.01, 'step': [20, 30, 40, 50], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 100, 'weight_decay': 0.001}

[ Wed Dec 14 07:34:59 2022 ] Training epoch: 1
[ Wed Dec 14 07:35:01 2022 ] 	Batch(0/12) done. Loss: 8.1702  lr:0.010000
[ Wed Dec 14 07:35:06 2022 ] 	Mean training loss: 4.2949.
[ Wed Dec 14 07:35:06 2022 ] 	Time consumption: [Data]23%, [Network]77%
[ Wed Dec 14 07:35:06 2022 ] Training epoch: 2
[ Wed Dec 14 07:35:08 2022 ] 	Batch(0/12) done. Loss: 2.3676  lr:0.010000
[ Wed Dec 14 07:35:13 2022 ] 	Mean training loss: 2.0559.
[ Wed Dec 14 07:35:13 2022 ] 	Time consumption: [Data]25%, [Network]75%
[ Wed Dec 14 07:35:13 2022 ] Training epoch: 3
[ Wed Dec 14 07:35:15 2022 ] 	Batch(0/12) done. Loss: 1.8264  lr:0.010000
[ Wed Dec 14 07:35:20 2022 ] 	Mean training loss: 1.6067.
[ Wed Dec 14 07:35:20 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:35:20 2022 ] Training epoch: 4
[ Wed Dec 14 07:35:23 2022 ] 	Batch(0/12) done. Loss: 1.8429  lr:0.010000
[ Wed Dec 14 07:35:28 2022 ] 	Mean training loss: 1.5583.
[ Wed Dec 14 07:35:28 2022 ] 	Time consumption: [Data]25%, [Network]74%
[ Wed Dec 14 07:35:28 2022 ] Training epoch: 5
[ Wed Dec 14 07:35:30 2022 ] 	Batch(0/12) done. Loss: 1.5436  lr:0.010000
[ Wed Dec 14 07:35:35 2022 ] 	Mean training loss: 1.3340.
[ Wed Dec 14 07:35:35 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:35:35 2022 ] Eval epoch: 5
[ Wed Dec 14 07:35:37 2022 ] 	Mean test loss of 3 batches: 1.799767017364502.
[ Wed Dec 14 07:35:37 2022 ] 	Top1: 55.93%
[ Wed Dec 14 07:35:37 2022 ] 	Top5: 96.61%
[ Wed Dec 14 07:35:37 2022 ] Training epoch: 6
[ Wed Dec 14 07:35:39 2022 ] 	Batch(0/12) done. Loss: 1.5555  lr:0.010000
[ Wed Dec 14 07:35:44 2022 ] 	Mean training loss: 1.1871.
[ Wed Dec 14 07:35:44 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:35:44 2022 ] Training epoch: 7
[ Wed Dec 14 07:35:47 2022 ] 	Batch(0/12) done. Loss: 1.6346  lr:0.010000
[ Wed Dec 14 07:35:52 2022 ] 	Mean training loss: 0.9990.
[ Wed Dec 14 07:35:52 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:35:52 2022 ] Training epoch: 8
[ Wed Dec 14 07:35:54 2022 ] 	Batch(0/12) done. Loss: 0.9915  lr:0.010000
[ Wed Dec 14 07:35:59 2022 ] 	Mean training loss: 1.0321.
[ Wed Dec 14 07:35:59 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:35:59 2022 ] Training epoch: 9
[ Wed Dec 14 07:36:01 2022 ] 	Batch(0/12) done. Loss: 1.4442  lr:0.010000
[ Wed Dec 14 07:36:06 2022 ] 	Mean training loss: 0.9715.
[ Wed Dec 14 07:36:06 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:36:06 2022 ] Training epoch: 10
[ Wed Dec 14 07:36:08 2022 ] 	Batch(0/12) done. Loss: 1.0708  lr:0.010000
[ Wed Dec 14 07:36:13 2022 ] 	Mean training loss: 0.7978.
[ Wed Dec 14 07:36:13 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:36:13 2022 ] Eval epoch: 10
[ Wed Dec 14 07:36:16 2022 ] 	Mean test loss of 3 batches: 1.7340599298477173.
[ Wed Dec 14 07:36:16 2022 ] 	Top1: 56.50%
[ Wed Dec 14 07:36:16 2022 ] 	Top5: 99.44%
[ Wed Dec 14 07:36:16 2022 ] Training epoch: 11
[ Wed Dec 14 07:36:18 2022 ] 	Batch(0/12) done. Loss: 0.9380  lr:0.010000
[ Wed Dec 14 07:36:23 2022 ] 	Mean training loss: 0.8239.
[ Wed Dec 14 07:36:23 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:36:23 2022 ] Training epoch: 12
[ Wed Dec 14 07:36:25 2022 ] 	Batch(0/12) done. Loss: 0.6475  lr:0.010000
[ Wed Dec 14 07:36:30 2022 ] 	Mean training loss: 0.6783.
[ Wed Dec 14 07:36:30 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:36:30 2022 ] Training epoch: 13
[ Wed Dec 14 07:36:32 2022 ] 	Batch(0/12) done. Loss: 0.7283  lr:0.010000
[ Wed Dec 14 07:36:37 2022 ] 	Mean training loss: 0.7281.
[ Wed Dec 14 07:36:37 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:36:37 2022 ] Training epoch: 14
[ Wed Dec 14 07:36:40 2022 ] 	Batch(0/12) done. Loss: 0.7084  lr:0.010000
[ Wed Dec 14 07:36:45 2022 ] 	Mean training loss: 0.6223.
[ Wed Dec 14 07:36:45 2022 ] 	Time consumption: [Data]26%, [Network]73%
[ Wed Dec 14 07:36:45 2022 ] Training epoch: 15
[ Wed Dec 14 07:36:47 2022 ] 	Batch(0/12) done. Loss: 0.9287  lr:0.010000
[ Wed Dec 14 07:36:52 2022 ] 	Mean training loss: 0.6261.
[ Wed Dec 14 07:36:52 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:36:52 2022 ] Eval epoch: 15
[ Wed Dec 14 07:36:54 2022 ] 	Mean test loss of 3 batches: 1.5291839838027954.
[ Wed Dec 14 07:36:54 2022 ] 	Top1: 53.67%
[ Wed Dec 14 07:36:54 2022 ] 	Top5: 99.44%
[ Wed Dec 14 07:36:54 2022 ] Training epoch: 16
[ Wed Dec 14 07:36:57 2022 ] 	Batch(0/12) done. Loss: 0.5781  lr:0.010000
[ Wed Dec 14 07:37:02 2022 ] 	Mean training loss: 0.6490.
[ Wed Dec 14 07:37:02 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:37:02 2022 ] Training epoch: 17
[ Wed Dec 14 07:37:04 2022 ] 	Batch(0/12) done. Loss: 0.5178  lr:0.010000
[ Wed Dec 14 07:37:09 2022 ] 	Mean training loss: 0.4959.
[ Wed Dec 14 07:37:09 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:37:09 2022 ] Training epoch: 18
[ Wed Dec 14 07:37:11 2022 ] 	Batch(0/12) done. Loss: 0.7142  lr:0.010000
[ Wed Dec 14 07:37:16 2022 ] 	Mean training loss: 0.5550.
[ Wed Dec 14 07:37:16 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:37:16 2022 ] Training epoch: 19
[ Wed Dec 14 07:37:18 2022 ] 	Batch(0/12) done. Loss: 0.5467  lr:0.010000
[ Wed Dec 14 07:37:23 2022 ] 	Mean training loss: 0.4372.
[ Wed Dec 14 07:37:23 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:37:23 2022 ] Training epoch: 20
[ Wed Dec 14 07:37:26 2022 ] 	Batch(0/12) done. Loss: 0.5432  lr:0.010000
[ Wed Dec 14 07:37:31 2022 ] 	Mean training loss: 0.4218.
[ Wed Dec 14 07:37:31 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:37:31 2022 ] Eval epoch: 20
[ Wed Dec 14 07:37:33 2022 ] 	Mean test loss of 3 batches: 0.6476067900657654.
[ Wed Dec 14 07:37:33 2022 ] 	Top1: 75.14%
[ Wed Dec 14 07:37:33 2022 ] 	Top5: 98.87%
[ Wed Dec 14 07:37:33 2022 ] Training epoch: 21
[ Wed Dec 14 07:37:35 2022 ] 	Batch(0/12) done. Loss: 0.4447  lr:0.001000
[ Wed Dec 14 07:37:40 2022 ] 	Mean training loss: 0.3650.
[ Wed Dec 14 07:37:40 2022 ] 	Time consumption: [Data]27%, [Network]73%
[ Wed Dec 14 07:37:40 2022 ] Training epoch: 22
[ Wed Dec 14 07:37:43 2022 ] 	Batch(0/12) done. Loss: 0.3064  lr:0.001000
[ Wed Dec 14 07:37:48 2022 ] 	Mean training loss: 0.3631.
[ Wed Dec 14 07:37:48 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:37:48 2022 ] Training epoch: 23
[ Wed Dec 14 07:37:50 2022 ] 	Batch(0/12) done. Loss: 0.3805  lr:0.001000
[ Wed Dec 14 07:37:55 2022 ] 	Mean training loss: 0.3480.
[ Wed Dec 14 07:37:55 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:37:55 2022 ] Training epoch: 24
[ Wed Dec 14 07:37:57 2022 ] 	Batch(0/12) done. Loss: 0.2306  lr:0.001000
[ Wed Dec 14 07:38:02 2022 ] 	Mean training loss: 0.2799.
[ Wed Dec 14 07:38:02 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:38:02 2022 ] Training epoch: 25
[ Wed Dec 14 07:38:04 2022 ] 	Batch(0/12) done. Loss: 0.3082  lr:0.001000
[ Wed Dec 14 07:38:09 2022 ] 	Mean training loss: 0.3119.
[ Wed Dec 14 07:38:09 2022 ] 	Time consumption: [Data]25%, [Network]75%
[ Wed Dec 14 07:38:09 2022 ] Eval epoch: 25
[ Wed Dec 14 07:38:12 2022 ] 	Mean test loss of 3 batches: 0.7252982258796692.
[ Wed Dec 14 07:38:12 2022 ] 	Top1: 76.27%
[ Wed Dec 14 07:38:12 2022 ] 	Top5: 100.00%
[ Wed Dec 14 07:38:12 2022 ] Training epoch: 26
[ Wed Dec 14 07:38:14 2022 ] 	Batch(0/12) done. Loss: 0.2726  lr:0.001000
[ Wed Dec 14 07:38:19 2022 ] 	Mean training loss: 0.3465.
[ Wed Dec 14 07:38:19 2022 ] 	Time consumption: [Data]25%, [Network]75%
[ Wed Dec 14 07:38:19 2022 ] Training epoch: 27
[ Wed Dec 14 07:38:21 2022 ] 	Batch(0/12) done. Loss: 0.2936  lr:0.001000
[ Wed Dec 14 07:38:26 2022 ] 	Mean training loss: 0.2921.
[ Wed Dec 14 07:38:26 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:38:26 2022 ] Training epoch: 28
[ Wed Dec 14 07:38:29 2022 ] 	Batch(0/12) done. Loss: 0.2544  lr:0.001000
[ Wed Dec 14 07:38:33 2022 ] 	Mean training loss: 0.2625.
[ Wed Dec 14 07:38:33 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:38:33 2022 ] Training epoch: 29
[ Wed Dec 14 07:38:36 2022 ] 	Batch(0/12) done. Loss: 0.3718  lr:0.001000
[ Wed Dec 14 07:38:41 2022 ] 	Mean training loss: 0.2863.
[ Wed Dec 14 07:38:41 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:38:41 2022 ] Training epoch: 30
[ Wed Dec 14 07:38:43 2022 ] 	Batch(0/12) done. Loss: 0.2498  lr:0.001000
[ Wed Dec 14 07:38:48 2022 ] 	Mean training loss: 0.2881.
[ Wed Dec 14 07:38:48 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:38:48 2022 ] Eval epoch: 30
[ Wed Dec 14 07:38:51 2022 ] 	Mean test loss of 3 batches: 0.628757655620575.
[ Wed Dec 14 07:38:51 2022 ] 	Top1: 81.36%
[ Wed Dec 14 07:38:51 2022 ] 	Top5: 100.00%
[ Wed Dec 14 07:38:51 2022 ] Training epoch: 31
[ Wed Dec 14 07:38:53 2022 ] 	Batch(0/12) done. Loss: 0.4508  lr:0.000100
[ Wed Dec 14 07:38:58 2022 ] 	Mean training loss: 0.2824.
[ Wed Dec 14 07:38:58 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:38:58 2022 ] Training epoch: 32
[ Wed Dec 14 07:39:00 2022 ] 	Batch(0/12) done. Loss: 0.3919  lr:0.000100
[ Wed Dec 14 07:39:05 2022 ] 	Mean training loss: 0.2700.
[ Wed Dec 14 07:39:05 2022 ] 	Time consumption: [Data]27%, [Network]73%
[ Wed Dec 14 07:39:05 2022 ] Training epoch: 33
[ Wed Dec 14 07:39:07 2022 ] 	Batch(0/12) done. Loss: 0.3406  lr:0.000100
[ Wed Dec 14 07:39:12 2022 ] 	Mean training loss: 0.2749.
[ Wed Dec 14 07:39:12 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:39:12 2022 ] Training epoch: 34
[ Wed Dec 14 07:39:14 2022 ] 	Batch(0/12) done. Loss: 0.2371  lr:0.000100
[ Wed Dec 14 07:39:19 2022 ] 	Mean training loss: 0.2691.
[ Wed Dec 14 07:39:19 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:39:19 2022 ] Training epoch: 35
[ Wed Dec 14 07:39:22 2022 ] 	Batch(0/12) done. Loss: 0.3378  lr:0.000100
[ Wed Dec 14 07:39:27 2022 ] 	Mean training loss: 0.2478.
[ Wed Dec 14 07:39:27 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:39:27 2022 ] Eval epoch: 35
[ Wed Dec 14 07:39:29 2022 ] 	Mean test loss of 3 batches: 0.6687243580818176.
[ Wed Dec 14 07:39:29 2022 ] 	Top1: 75.71%
[ Wed Dec 14 07:39:29 2022 ] 	Top5: 100.00%
[ Wed Dec 14 07:39:29 2022 ] Training epoch: 36
[ Wed Dec 14 07:39:31 2022 ] 	Batch(0/12) done. Loss: 0.2222  lr:0.000100
[ Wed Dec 14 07:39:36 2022 ] 	Mean training loss: 0.2469.
[ Wed Dec 14 07:39:36 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:39:36 2022 ] Training epoch: 37
[ Wed Dec 14 07:39:38 2022 ] 	Batch(0/12) done. Loss: 0.3645  lr:0.000100
[ Wed Dec 14 07:39:43 2022 ] 	Mean training loss: 0.2831.
[ Wed Dec 14 07:39:43 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:39:43 2022 ] Training epoch: 38
[ Wed Dec 14 07:39:46 2022 ] 	Batch(0/12) done. Loss: 0.1963  lr:0.000100
[ Wed Dec 14 07:39:51 2022 ] 	Mean training loss: 0.2384.
[ Wed Dec 14 07:39:51 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:39:51 2022 ] Training epoch: 39
[ Wed Dec 14 07:39:53 2022 ] 	Batch(0/12) done. Loss: 0.2698  lr:0.000100
[ Wed Dec 14 07:39:58 2022 ] 	Mean training loss: 0.2508.
[ Wed Dec 14 07:39:58 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:39:58 2022 ] Training epoch: 40
[ Wed Dec 14 07:40:00 2022 ] 	Batch(0/12) done. Loss: 0.2139  lr:0.000100
[ Wed Dec 14 07:40:05 2022 ] 	Mean training loss: 0.2587.
[ Wed Dec 14 07:40:05 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:40:05 2022 ] Eval epoch: 40
[ Wed Dec 14 07:40:07 2022 ] 	Mean test loss of 3 batches: 0.6699721813201904.
[ Wed Dec 14 07:40:07 2022 ] 	Top1: 81.92%
[ Wed Dec 14 07:40:07 2022 ] 	Top5: 99.44%
[ Wed Dec 14 07:40:07 2022 ] Training epoch: 41
[ Wed Dec 14 07:40:10 2022 ] 	Batch(0/12) done. Loss: 0.1765  lr:0.000010
[ Wed Dec 14 07:40:15 2022 ] 	Mean training loss: 0.2625.
[ Wed Dec 14 07:40:15 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:40:15 2022 ] Training epoch: 42
[ Wed Dec 14 07:40:17 2022 ] 	Batch(0/12) done. Loss: 0.3248  lr:0.000010
[ Wed Dec 14 07:40:22 2022 ] 	Mean training loss: 0.2668.
[ Wed Dec 14 07:40:22 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:40:22 2022 ] Training epoch: 43
[ Wed Dec 14 07:40:24 2022 ] 	Batch(0/12) done. Loss: 0.2457  lr:0.000010
[ Wed Dec 14 07:40:29 2022 ] 	Mean training loss: 0.2506.
[ Wed Dec 14 07:40:29 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:40:29 2022 ] Training epoch: 44
[ Wed Dec 14 07:40:31 2022 ] 	Batch(0/12) done. Loss: 0.4526  lr:0.000010
[ Wed Dec 14 07:40:36 2022 ] 	Mean training loss: 0.2433.
[ Wed Dec 14 07:40:36 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:40:36 2022 ] Training epoch: 45
[ Wed Dec 14 07:40:38 2022 ] 	Batch(0/12) done. Loss: 0.2439  lr:0.000010
[ Wed Dec 14 07:40:43 2022 ] 	Mean training loss: 0.2426.
[ Wed Dec 14 07:40:43 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:40:43 2022 ] Eval epoch: 45
[ Wed Dec 14 07:40:46 2022 ] 	Mean test loss of 3 batches: 0.7222240567207336.
[ Wed Dec 14 07:40:46 2022 ] 	Top1: 77.97%
[ Wed Dec 14 07:40:46 2022 ] 	Top5: 100.00%
[ Wed Dec 14 07:40:46 2022 ] Training epoch: 46
[ Wed Dec 14 07:40:48 2022 ] 	Batch(0/12) done. Loss: 0.1554  lr:0.000010
[ Wed Dec 14 07:40:53 2022 ] 	Mean training loss: 0.3112.
[ Wed Dec 14 07:40:53 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:40:53 2022 ] Training epoch: 47
[ Wed Dec 14 07:40:55 2022 ] 	Batch(0/12) done. Loss: 0.2976  lr:0.000010
[ Wed Dec 14 07:41:00 2022 ] 	Mean training loss: 0.2440.
[ Wed Dec 14 07:41:00 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:41:00 2022 ] Training epoch: 48
[ Wed Dec 14 07:41:02 2022 ] 	Batch(0/12) done. Loss: 0.2828  lr:0.000010
[ Wed Dec 14 07:41:07 2022 ] 	Mean training loss: 0.2535.
[ Wed Dec 14 07:41:07 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:41:07 2022 ] Training epoch: 49
[ Wed Dec 14 07:41:09 2022 ] 	Batch(0/12) done. Loss: 0.1487  lr:0.000010
[ Wed Dec 14 07:41:14 2022 ] 	Mean training loss: 0.2498.
[ Wed Dec 14 07:41:14 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:41:14 2022 ] Training epoch: 50
[ Wed Dec 14 07:41:17 2022 ] 	Batch(0/12) done. Loss: 0.2126  lr:0.000010
[ Wed Dec 14 07:41:21 2022 ] 	Mean training loss: 0.2580.
[ Wed Dec 14 07:41:21 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:41:22 2022 ] Eval epoch: 50
[ Wed Dec 14 07:41:24 2022 ] 	Mean test loss of 3 batches: 0.6637545228004456.
[ Wed Dec 14 07:41:24 2022 ] 	Top1: 77.97%
[ Wed Dec 14 07:41:24 2022 ] 	Top5: 100.00%
[ Wed Dec 14 07:41:24 2022 ] Training epoch: 51
[ Wed Dec 14 07:41:26 2022 ] 	Batch(0/12) done. Loss: 0.1630  lr:0.000001
[ Wed Dec 14 07:41:31 2022 ] 	Mean training loss: 0.2407.
[ Wed Dec 14 07:41:31 2022 ] 	Time consumption: [Data]25%, [Network]74%
[ Wed Dec 14 07:41:31 2022 ] Training epoch: 52
[ Wed Dec 14 07:41:33 2022 ] 	Batch(0/12) done. Loss: 0.2622  lr:0.000001
[ Wed Dec 14 07:41:38 2022 ] 	Mean training loss: 0.2555.
[ Wed Dec 14 07:41:38 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:41:38 2022 ] Training epoch: 53
[ Wed Dec 14 07:41:41 2022 ] 	Batch(0/12) done. Loss: 0.2454  lr:0.000001
[ Wed Dec 14 07:41:46 2022 ] 	Mean training loss: 0.2640.
[ Wed Dec 14 07:41:46 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:41:46 2022 ] Training epoch: 54
[ Wed Dec 14 07:41:48 2022 ] 	Batch(0/12) done. Loss: 0.1778  lr:0.000001
[ Wed Dec 14 07:41:53 2022 ] 	Mean training loss: 0.2721.
[ Wed Dec 14 07:41:53 2022 ] 	Time consumption: [Data]25%, [Network]75%
[ Wed Dec 14 07:41:53 2022 ] Training epoch: 55
[ Wed Dec 14 07:41:55 2022 ] 	Batch(0/12) done. Loss: 0.1902  lr:0.000001
[ Wed Dec 14 07:42:00 2022 ] 	Mean training loss: 0.2272.
[ Wed Dec 14 07:42:00 2022 ] 	Time consumption: [Data]25%, [Network]75%
[ Wed Dec 14 07:42:00 2022 ] Eval epoch: 55
[ Wed Dec 14 07:42:02 2022 ] 	Mean test loss of 3 batches: 0.6667270064353943.
[ Wed Dec 14 07:42:02 2022 ] 	Top1: 81.92%
[ Wed Dec 14 07:42:02 2022 ] 	Top5: 99.44%
[ Wed Dec 14 07:42:02 2022 ] Training epoch: 56
[ Wed Dec 14 07:42:04 2022 ] 	Batch(0/12) done. Loss: 0.2549  lr:0.000001
[ Wed Dec 14 07:42:09 2022 ] 	Mean training loss: 0.2730.
[ Wed Dec 14 07:42:09 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:42:09 2022 ] Training epoch: 57
[ Wed Dec 14 07:42:12 2022 ] 	Batch(0/12) done. Loss: 0.2914  lr:0.000001
[ Wed Dec 14 07:42:17 2022 ] 	Mean training loss: 0.2691.
[ Wed Dec 14 07:42:17 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:42:17 2022 ] Training epoch: 58
[ Wed Dec 14 07:42:19 2022 ] 	Batch(0/12) done. Loss: 0.3436  lr:0.000001
[ Wed Dec 14 07:42:24 2022 ] 	Mean training loss: 0.3077.
[ Wed Dec 14 07:42:24 2022 ] 	Time consumption: [Data]25%, [Network]75%
[ Wed Dec 14 07:42:24 2022 ] Training epoch: 59
[ Wed Dec 14 07:42:26 2022 ] 	Batch(0/12) done. Loss: 0.1604  lr:0.000001
[ Wed Dec 14 07:42:31 2022 ] 	Mean training loss: 0.2747.
[ Wed Dec 14 07:42:31 2022 ] 	Time consumption: [Data]25%, [Network]75%
[ Wed Dec 14 07:42:31 2022 ] Training epoch: 60
[ Wed Dec 14 07:42:33 2022 ] 	Batch(0/12) done. Loss: 0.3284  lr:0.000001
[ Wed Dec 14 07:42:38 2022 ] 	Mean training loss: 0.2710.
[ Wed Dec 14 07:42:38 2022 ] 	Time consumption: [Data]27%, [Network]73%
[ Wed Dec 14 07:42:38 2022 ] Eval epoch: 60
[ Wed Dec 14 07:42:40 2022 ] 	Mean test loss of 3 batches: 0.6598398089408875.
[ Wed Dec 14 07:42:40 2022 ] 	Top1: 78.53%
[ Wed Dec 14 07:42:40 2022 ] 	Top5: 100.00%
[ Wed Dec 14 07:42:40 2022 ] Training epoch: 61
[ Wed Dec 14 07:42:43 2022 ] 	Batch(0/12) done. Loss: 0.2871  lr:0.000001
[ Wed Dec 14 07:42:48 2022 ] 	Mean training loss: 0.2457.
[ Wed Dec 14 07:42:48 2022 ] 	Time consumption: [Data]26%, [Network]73%
[ Wed Dec 14 07:42:48 2022 ] Training epoch: 62
[ Wed Dec 14 07:42:50 2022 ] 	Batch(0/12) done. Loss: 0.2364  lr:0.000001
[ Wed Dec 14 07:42:55 2022 ] 	Mean training loss: 0.2565.
[ Wed Dec 14 07:42:55 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:42:55 2022 ] Training epoch: 63
[ Wed Dec 14 07:42:57 2022 ] 	Batch(0/12) done. Loss: 0.1915  lr:0.000001
[ Wed Dec 14 07:43:02 2022 ] 	Mean training loss: 0.2283.
[ Wed Dec 14 07:43:02 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:43:02 2022 ] Training epoch: 64
[ Wed Dec 14 07:43:04 2022 ] 	Batch(0/12) done. Loss: 0.2347  lr:0.000001
[ Wed Dec 14 07:43:09 2022 ] 	Mean training loss: 0.2741.
[ Wed Dec 14 07:43:09 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:43:09 2022 ] Training epoch: 65
[ Wed Dec 14 07:43:11 2022 ] 	Batch(0/12) done. Loss: 0.2580  lr:0.000001
[ Wed Dec 14 07:43:16 2022 ] 	Mean training loss: 0.2674.
[ Wed Dec 14 07:43:16 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:43:16 2022 ] Eval epoch: 65
[ Wed Dec 14 07:43:19 2022 ] 	Mean test loss of 3 batches: 0.6805527806282043.
[ Wed Dec 14 07:43:19 2022 ] 	Top1: 77.40%
[ Wed Dec 14 07:43:19 2022 ] 	Top5: 99.44%
[ Wed Dec 14 07:43:19 2022 ] Training epoch: 66
[ Wed Dec 14 07:43:21 2022 ] 	Batch(0/12) done. Loss: 0.2445  lr:0.000001
[ Wed Dec 14 07:43:26 2022 ] 	Mean training loss: 0.2589.
[ Wed Dec 14 07:43:26 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:43:26 2022 ] Training epoch: 67
[ Wed Dec 14 07:43:28 2022 ] 	Batch(0/12) done. Loss: 0.2925  lr:0.000001
[ Wed Dec 14 07:43:33 2022 ] 	Mean training loss: 0.2661.
[ Wed Dec 14 07:43:33 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:43:33 2022 ] Training epoch: 68
[ Wed Dec 14 07:43:36 2022 ] 	Batch(0/12) done. Loss: 0.1402  lr:0.000001
[ Wed Dec 14 07:43:41 2022 ] 	Mean training loss: 0.2617.
[ Wed Dec 14 07:43:41 2022 ] 	Time consumption: [Data]28%, [Network]72%
[ Wed Dec 14 07:43:41 2022 ] Training epoch: 69
[ Wed Dec 14 07:43:43 2022 ] 	Batch(0/12) done. Loss: 0.2199  lr:0.000001
[ Wed Dec 14 07:43:48 2022 ] 	Mean training loss: 0.2635.
[ Wed Dec 14 07:43:48 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:43:48 2022 ] Training epoch: 70
[ Wed Dec 14 07:43:50 2022 ] 	Batch(0/12) done. Loss: 0.4327  lr:0.000001
[ Wed Dec 14 07:43:55 2022 ] 	Mean training loss: 0.2758.
[ Wed Dec 14 07:43:55 2022 ] 	Time consumption: [Data]25%, [Network]75%
[ Wed Dec 14 07:43:55 2022 ] Eval epoch: 70
[ Wed Dec 14 07:43:58 2022 ] 	Mean test loss of 3 batches: 0.6691638827323914.
[ Wed Dec 14 07:43:58 2022 ] 	Top1: 79.66%
[ Wed Dec 14 07:43:58 2022 ] 	Top5: 100.00%
[ Wed Dec 14 07:43:58 2022 ] Training epoch: 71
[ Wed Dec 14 07:44:00 2022 ] 	Batch(0/12) done. Loss: 0.2174  lr:0.000001
[ Wed Dec 14 07:44:05 2022 ] 	Mean training loss: 0.2614.
[ Wed Dec 14 07:44:05 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:44:05 2022 ] Training epoch: 72
[ Wed Dec 14 07:44:07 2022 ] 	Batch(0/12) done. Loss: 0.1468  lr:0.000001
[ Wed Dec 14 07:44:12 2022 ] 	Mean training loss: 0.2553.
[ Wed Dec 14 07:44:12 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:44:12 2022 ] Training epoch: 73
[ Wed Dec 14 07:44:14 2022 ] 	Batch(0/12) done. Loss: 0.1840  lr:0.000001
[ Wed Dec 14 07:44:20 2022 ] 	Mean training loss: 0.2467.
[ Wed Dec 14 07:44:20 2022 ] 	Time consumption: [Data]25%, [Network]75%
[ Wed Dec 14 07:44:20 2022 ] Training epoch: 74
[ Wed Dec 14 07:44:22 2022 ] 	Batch(0/12) done. Loss: 0.2978  lr:0.000001
[ Wed Dec 14 07:44:27 2022 ] 	Mean training loss: 0.2801.
[ Wed Dec 14 07:44:27 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:44:27 2022 ] Training epoch: 75
[ Wed Dec 14 07:44:29 2022 ] 	Batch(0/12) done. Loss: 0.2395  lr:0.000001
[ Wed Dec 14 07:44:34 2022 ] 	Mean training loss: 0.2679.
[ Wed Dec 14 07:44:34 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:44:34 2022 ] Eval epoch: 75
[ Wed Dec 14 07:44:37 2022 ] 	Mean test loss of 3 batches: 0.6821960806846619.
[ Wed Dec 14 07:44:37 2022 ] 	Top1: 81.92%
[ Wed Dec 14 07:44:37 2022 ] 	Top5: 99.44%
[ Wed Dec 14 07:44:37 2022 ] Training epoch: 76
[ Wed Dec 14 07:44:39 2022 ] 	Batch(0/12) done. Loss: 0.3747  lr:0.000001
[ Wed Dec 14 07:44:44 2022 ] 	Mean training loss: 0.2693.
[ Wed Dec 14 07:44:44 2022 ] 	Time consumption: [Data]25%, [Network]75%
[ Wed Dec 14 07:44:44 2022 ] Training epoch: 77
[ Wed Dec 14 07:44:46 2022 ] 	Batch(0/12) done. Loss: 0.2266  lr:0.000001
[ Wed Dec 14 07:44:51 2022 ] 	Mean training loss: 0.2601.
[ Wed Dec 14 07:44:51 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:44:51 2022 ] Training epoch: 78
[ Wed Dec 14 07:44:53 2022 ] 	Batch(0/12) done. Loss: 0.2328  lr:0.000001
[ Wed Dec 14 07:44:58 2022 ] 	Mean training loss: 0.2761.
[ Wed Dec 14 07:44:58 2022 ] 	Time consumption: [Data]27%, [Network]73%
[ Wed Dec 14 07:44:58 2022 ] Training epoch: 79
[ Wed Dec 14 07:45:00 2022 ] 	Batch(0/12) done. Loss: 0.1992  lr:0.000001
[ Wed Dec 14 07:45:05 2022 ] 	Mean training loss: 0.2782.
[ Wed Dec 14 07:45:05 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:45:05 2022 ] Training epoch: 80
[ Wed Dec 14 07:45:08 2022 ] 	Batch(0/12) done. Loss: 0.3212  lr:0.000001
[ Wed Dec 14 07:45:13 2022 ] 	Mean training loss: 0.2514.
[ Wed Dec 14 07:45:13 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:45:13 2022 ] Eval epoch: 80
[ Wed Dec 14 07:45:15 2022 ] 	Mean test loss of 3 batches: 0.696615993976593.
[ Wed Dec 14 07:45:15 2022 ] 	Top1: 76.84%
[ Wed Dec 14 07:45:15 2022 ] 	Top5: 100.00%
[ Wed Dec 14 07:45:15 2022 ] Training epoch: 81
[ Wed Dec 14 07:45:17 2022 ] 	Batch(0/12) done. Loss: 0.2002  lr:0.000001
[ Wed Dec 14 07:45:22 2022 ] 	Mean training loss: 0.2601.
[ Wed Dec 14 07:45:22 2022 ] 	Time consumption: [Data]27%, [Network]73%
[ Wed Dec 14 07:45:22 2022 ] Training epoch: 82
[ Wed Dec 14 07:45:25 2022 ] 	Batch(0/12) done. Loss: 0.2576  lr:0.000001
[ Wed Dec 14 07:45:30 2022 ] 	Mean training loss: 0.2866.
[ Wed Dec 14 07:45:30 2022 ] 	Time consumption: [Data]27%, [Network]73%
[ Wed Dec 14 07:45:30 2022 ] Training epoch: 83
[ Wed Dec 14 07:45:32 2022 ] 	Batch(0/12) done. Loss: 0.1748  lr:0.000001
[ Wed Dec 14 07:45:37 2022 ] 	Mean training loss: 0.2768.
[ Wed Dec 14 07:45:37 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:45:37 2022 ] Training epoch: 84
[ Wed Dec 14 07:45:39 2022 ] 	Batch(0/12) done. Loss: 0.3025  lr:0.000001
[ Wed Dec 14 07:45:44 2022 ] 	Mean training loss: 0.2601.
[ Wed Dec 14 07:45:44 2022 ] 	Time consumption: [Data]27%, [Network]73%
[ Wed Dec 14 07:45:44 2022 ] Training epoch: 85
[ Wed Dec 14 07:45:46 2022 ] 	Batch(0/12) done. Loss: 0.2463  lr:0.000001
[ Wed Dec 14 07:45:51 2022 ] 	Mean training loss: 0.2325.
[ Wed Dec 14 07:45:51 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:45:51 2022 ] Eval epoch: 85
[ Wed Dec 14 07:45:54 2022 ] 	Mean test loss of 3 batches: 0.6873297691345215.
[ Wed Dec 14 07:45:54 2022 ] 	Top1: 77.97%
[ Wed Dec 14 07:45:54 2022 ] 	Top5: 100.00%
[ Wed Dec 14 07:45:54 2022 ] Training epoch: 86
[ Wed Dec 14 07:45:56 2022 ] 	Batch(0/12) done. Loss: 0.2494  lr:0.000001
[ Wed Dec 14 07:46:01 2022 ] 	Mean training loss: 0.2679.
[ Wed Dec 14 07:46:01 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:46:01 2022 ] Training epoch: 87
[ Wed Dec 14 07:46:03 2022 ] 	Batch(0/12) done. Loss: 0.2770  lr:0.000001
[ Wed Dec 14 07:46:08 2022 ] 	Mean training loss: 0.2567.
[ Wed Dec 14 07:46:08 2022 ] 	Time consumption: [Data]26%, [Network]73%
[ Wed Dec 14 07:46:08 2022 ] Training epoch: 88
[ Wed Dec 14 07:46:10 2022 ] 	Batch(0/12) done. Loss: 0.2502  lr:0.000001
[ Wed Dec 14 07:46:15 2022 ] 	Mean training loss: 0.2559.
[ Wed Dec 14 07:46:15 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:46:15 2022 ] Training epoch: 89
[ Wed Dec 14 07:46:18 2022 ] 	Batch(0/12) done. Loss: 0.2411  lr:0.000001
[ Wed Dec 14 07:46:23 2022 ] 	Mean training loss: 0.2572.
[ Wed Dec 14 07:46:23 2022 ] 	Time consumption: [Data]27%, [Network]73%
[ Wed Dec 14 07:46:23 2022 ] Training epoch: 90
[ Wed Dec 14 07:46:25 2022 ] 	Batch(0/12) done. Loss: 0.2612  lr:0.000001
[ Wed Dec 14 07:46:30 2022 ] 	Mean training loss: 0.2551.
[ Wed Dec 14 07:46:30 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:46:30 2022 ] Eval epoch: 90
[ Wed Dec 14 07:46:32 2022 ] 	Mean test loss of 3 batches: 0.6825030446052551.
[ Wed Dec 14 07:46:32 2022 ] 	Top1: 78.53%
[ Wed Dec 14 07:46:32 2022 ] 	Top5: 100.00%
[ Wed Dec 14 07:46:32 2022 ] Training epoch: 91
[ Wed Dec 14 07:46:35 2022 ] 	Batch(0/12) done. Loss: 0.3138  lr:0.000001
[ Wed Dec 14 07:46:40 2022 ] 	Mean training loss: 0.2751.
[ Wed Dec 14 07:46:40 2022 ] 	Time consumption: [Data]26%, [Network]73%
[ Wed Dec 14 07:46:40 2022 ] Training epoch: 92
[ Wed Dec 14 07:46:42 2022 ] 	Batch(0/12) done. Loss: 0.2464  lr:0.000001
[ Wed Dec 14 07:46:47 2022 ] 	Mean training loss: 0.2932.
[ Wed Dec 14 07:46:47 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:46:47 2022 ] Training epoch: 93
[ Wed Dec 14 07:46:49 2022 ] 	Batch(0/12) done. Loss: 0.3417  lr:0.000001
[ Wed Dec 14 07:46:54 2022 ] 	Mean training loss: 0.3126.
[ Wed Dec 14 07:46:54 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:46:54 2022 ] Training epoch: 94
[ Wed Dec 14 07:46:56 2022 ] 	Batch(0/12) done. Loss: 0.2839  lr:0.000001
[ Wed Dec 14 07:47:01 2022 ] 	Mean training loss: 0.2518.
[ Wed Dec 14 07:47:01 2022 ] 	Time consumption: [Data]27%, [Network]73%
[ Wed Dec 14 07:47:01 2022 ] Training epoch: 95
[ Wed Dec 14 07:47:03 2022 ] 	Batch(0/12) done. Loss: 0.3023  lr:0.000001
[ Wed Dec 14 07:47:08 2022 ] 	Mean training loss: 0.2667.
[ Wed Dec 14 07:47:08 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:47:08 2022 ] Eval epoch: 95
[ Wed Dec 14 07:47:11 2022 ] 	Mean test loss of 3 batches: 0.654549241065979.
[ Wed Dec 14 07:47:11 2022 ] 	Top1: 77.97%
[ Wed Dec 14 07:47:11 2022 ] 	Top5: 100.00%
[ Wed Dec 14 07:47:11 2022 ] Training epoch: 96
[ Wed Dec 14 07:47:13 2022 ] 	Batch(0/12) done. Loss: 0.2028  lr:0.000001
[ Wed Dec 14 07:47:18 2022 ] 	Mean training loss: 0.2747.
[ Wed Dec 14 07:47:18 2022 ] 	Time consumption: [Data]26%, [Network]73%
[ Wed Dec 14 07:47:18 2022 ] Training epoch: 97
[ Wed Dec 14 07:47:20 2022 ] 	Batch(0/12) done. Loss: 0.2936  lr:0.000001
[ Wed Dec 14 07:47:25 2022 ] 	Mean training loss: 0.2776.
[ Wed Dec 14 07:47:25 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:47:25 2022 ] Training epoch: 98
[ Wed Dec 14 07:47:27 2022 ] 	Batch(0/12) done. Loss: 0.1842  lr:0.000001
[ Wed Dec 14 07:47:32 2022 ] 	Mean training loss: 0.2660.
[ Wed Dec 14 07:47:32 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:47:32 2022 ] Training epoch: 99
[ Wed Dec 14 07:47:35 2022 ] 	Batch(0/12) done. Loss: 0.1719  lr:0.000001
[ Wed Dec 14 07:47:39 2022 ] 	Mean training loss: 0.2764.
[ Wed Dec 14 07:47:39 2022 ] 	Time consumption: [Data]26%, [Network]74%
[ Wed Dec 14 07:47:39 2022 ] Training epoch: 100
[ Wed Dec 14 07:47:42 2022 ] 	Batch(0/12) done. Loss: 0.2323  lr:0.000001
[ Wed Dec 14 07:47:47 2022 ] 	Mean training loss: 0.2451.
[ Wed Dec 14 07:47:47 2022 ] 	Time consumption: [Data]25%, [Network]75%
[ Wed Dec 14 07:47:47 2022 ] Eval epoch: 100
[ Wed Dec 14 07:47:49 2022 ] 	Mean test loss of 3 batches: 0.6642623543739319.
[ Wed Dec 14 07:47:49 2022 ] 	Top1: 78.53%
[ Wed Dec 14 07:47:49 2022 ] 	Top5: 100.00%
